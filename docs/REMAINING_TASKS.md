# OderWhat v2.0 - å‰©é¤˜é–‹ç™¼ä»»å‹™æ¸…å–®

**æœ€å¾Œæ›´æ–°**: 2025-12-03
**ç•¶å‰ç‹€æ…‹**: Phase 1 éƒ¨åˆ†å®Œæˆï¼Œéœ€ç¹¼çºŒé–‹ç™¼ Phase 1-3

---

## ğŸ“‹ å·²å®Œæˆçš„å·¥ä½œ

### âœ… Phase 0: åŸºç¤æ¶æ§‹é‡æ§‹ï¼ˆå·²å®Œæˆï¼‰
1. å»ºç«‹æ–°çš„åˆ†å±¤å¼ç®¡ç·šæ¶æ§‹
   - `services/pipeline/providers.py` - è³‡æ–™ç²å–å±¤
   - `services/pipeline/intelligence.py` - AI è™•ç†å±¤
   - `services/pipeline/orchestrator.py` - æµç¨‹å”èª¿å±¤
   - `schemas/pipeline.py` - ä¸­é–“è³‡æ–™çµæ§‹

2. ä¿®æ­£é…ç½®éŒ¯èª¤
   - âœ… ä½¿ç”¨ `gemini-1.5-flash` (Vision)
   - âœ… ä½¿ç”¨ `searchStringsArray` (Apify)
   - âœ… ä½¿ç”¨ HTTP ç›´æ¥å‘¼å« Serper.dev
   - âœ… åœ–ç‰‡ Base64 ç·¨ç¢¼

3. æ–°å¢ `DishAttributes` çµæ§‹
   - âœ… å·²åœ¨ `schemas/restaurant_profile.py` å®šç¾©å®Œæ•´å±¬æ€§
   - âœ… å·²æ›´æ–° `MenuItem` schema åŠ å…¥ `analysis` æ¬„ä½

---

## âš ï¸ ç•¶å‰å•é¡Œ

**ç·Šæ€¥**: Cloud Run éƒ¨ç½²å¾Œ API è«‹æ±‚è¶…æ™‚/æ›èµ·
- **Revision**: `oderwhat-staging-00031-9bk`
- **ç—‡ç‹€**: API è«‹æ±‚ç„¡å›æ‡‰
- **å¯èƒ½åŸå› **:
  - Import éŒ¯èª¤ï¼ˆæ–°æ¨¡çµ„å°å…¥å•é¡Œï¼‰
  - ç’°å¢ƒè®Šæ•¸ç¼ºå¤±
  - éåŒæ­¥é‚è¼¯éŒ¯èª¤
- **éœ€è¦åš**: æŸ¥çœ‹ Cloud Run æ—¥èªŒæ‰¾å‡ºéŒ¯èª¤

**æŸ¥çœ‹æ—¥èªŒ**:
```
https://console.cloud.google.com/run/detail/asia-east1/oderwhat-staging/logs?project=gen-lang-client-0415289079
```

æœå°‹é—œéµå­—: `ERROR`, `Exception`, `Pipeline`, `Aggregator`

---

## ğŸ¯ å¾…å®Œæˆä»»å‹™

### Phase 1: å®Œå–„ AI å±¬æ€§æ¨™è¨»ï¼ˆæœ€å„ªå…ˆï¼‰

#### Task 3: å¯¦ä½œ `MenuIntelligence.analyze_dish_batch()`

**æª”æ¡ˆ**: `services/pipeline/intelligence.py`

**ç›®æ¨™**: æ–°å¢ `MenuIntelligence` classï¼Œå¯¦ä½œæ‰¹æ¬¡å±¬æ€§åˆ†æ

**å¯¦ä½œå…§å®¹**:

```python
class MenuIntelligence:
    """
    Advanced AI tagging for dish attributes
    """

    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY environment variable not set")
        genai.configure(api_key=self.api_key)

    async def analyze_dish_batch(
        self,
        dishes: List[ParsedMenuItem],
        reviews: List[RawReview]
    ) -> List[DishAttributes]:
        """
        ä½¿ç”¨ Gemini AI æ‰¹æ¬¡åˆ†æèœè‰²å±¬æ€§

        Args:
            dishes: å·²è§£æçš„èœå–®é …ç›®åˆ—è¡¨
            reviews: é¡§å®¢è©•è«–åˆ—è¡¨

        Returns:
            List of DishAttributes (æ¯é“èœçš„çµæ§‹åŒ–å±¬æ€§)
        """
```

**System Prompt ç¯„æœ¬**:

```python
prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é£Ÿå“ç§‘å­¸å®¶èˆ‡æ•¸æ“šåˆ†æå¸«ã€‚

ä»»å‹™ï¼šåˆ†æèœå–®é …ç›®ä¸¦æ¨™è¨»çµæ§‹åŒ–å±¬æ€§ã€‚

èœå–®é …ç›®ï¼š
{json.dumps([{"name": d.name, "description": d.description} for d in dishes], ensure_ascii=False)}

é¡§å®¢è©•è«–æ‘˜è¦ï¼ˆåƒè€ƒç”¨ï¼‰ï¼š
{json.dumps([r.text[:100] for r in reviews[:10]], ensure_ascii=False)}

è«‹ç‚ºæ¯é“èœè¼¸å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š

{{
  "dish_attributes": [
    {{
      "dish_name": "å®®ä¿é›ä¸",

      // ç¡¬éæ¿¾å±¬æ€§ï¼ˆçµ•å°åˆ¤æ–·ï¼Œä¸ç¢ºå®šå‰‡æ¨™ falseï¼‰
      "is_spicy": true,
      "is_vegan": false,
      "contains_beef": false,
      "contains_pork": false,
      "contains_seafood": false,
      "allergens": ["peanuts"],

      // è»Ÿæ’åºå±¬æ€§
      "flavors": ["spicy", "savory", "garlic_heavy"],
      "textures": ["crispy", "tender"],
      "temperature": "hot",
      "cooking_method": "stir_fried",
      "suitable_occasions": ["group_share", "alcohol_pairing"],

      // åƒ¹å€¼å±¬æ€§
      "is_signature": true,
      "sentiment_score": 0.8,
      "highlight_review": "ç¶²å‹å¤§æ¨ï¼šå¤–çš®é…¥è„†ï¼ŒèŠ±ç”Ÿé¦™æ°£åè¶³"
    }}
  ]
}}

é‡è¦è¦å‰‡ï¼š
1. æˆåˆ†æª¢æ¸¬å¿…é ˆåš´æ ¼ï¼šç„¡æ³•ç¢ºå®šçš„æ¨™ç¤º false
2. éæ•åŸåªåˆ—å‡ºæ˜ç¢ºçš„ï¼ˆå …æœã€æµ·é®®ã€ä¹³è£½å“ç­‰ï¼‰
3. sentiment_score ç¯„åœ -1.0 åˆ° 1.0ï¼ˆæ ¹æ“šè©•è«–æƒ…æ„Ÿï¼‰
4. highlight_review åªæœ‰åœ¨è©•è«–æ˜ç¢ºæåŠæ™‚æ‰å¡«å…¥
"""
```

**éŒ¯èª¤è™•ç†**:
- JSON è§£æå¤±æ•— â†’ å›å‚³é è¨­å±¬æ€§ï¼ˆå…¨ false/emptyï¼‰
- API éŒ¯èª¤ â†’ è¨˜éŒ„éŒ¯èª¤ä¸¦å›å‚³ç©ºåˆ—è¡¨

---

#### Task 4: æ•´åˆå±¬æ€§æ¨™è¨»åˆ°ç®¡ç·š

**æª”æ¡ˆ**: `services/pipeline/orchestrator.py`

**ä¿®æ”¹ä½ç½®**: `RestaurantPipeline.process()` æ–¹æ³•ä¸­çš„ STEP 3

**ç•¶å‰ç¨‹å¼ç¢¼** (ç´„åœ¨ line 70-80):

```python
# STEP 3: Review fusion
print(f"\n[Pipeline] STEP 3: Fusing reviews with menu...")

enhanced_menu, review_summary = await self.insight_engine.fuse_reviews(
    menu_items=menu_items,
    reviews=map_data.reviews
)
```

**éœ€è¦æ”¹ç‚º**:

```python
# STEP 3: AI Attribute Tagging + Review fusion
print(f"\n[Pipeline] STEP 3: AI analysis and review fusion...")

# 3.1: å±¬æ€§æ¨™è¨»
intelligence = MenuIntelligence()
dish_attributes = await intelligence.analyze_dish_batch(
    dishes=menu_items,
    reviews=map_data.reviews
)

# 3.2: è©•è«–èåˆï¼ˆä¿ç•™åŸæœ‰é‚è¼¯ï¼Œä½†æ•´åˆå±¬æ€§ï¼‰
enhanced_menu, review_summary = await self.insight_engine.fuse_reviews(
    menu_items=menu_items,
    reviews=map_data.reviews
)

# 3.3: å°‡å±¬æ€§ç¶å®šåˆ°èœå–®é …ç›®
for idx, item in enumerate(enhanced_menu):
    if idx < len(dish_attributes):
        item.analysis = dish_attributes[idx]
    # ç”Ÿæˆ unique ID
    item.id = f"{map_data.place_id}_{idx}_{item.name[:10]}"
```

**æ³¨æ„äº‹é …**:
- Import `MenuIntelligence` from `intelligence.py`
- Import `DishAttributes` from `schemas.restaurant_profile`

---

### Phase 2: å»ºç«‹å³æ™‚æ¨è–¦ç³»çµ±

#### Task 5: å»ºç«‹ `UserInputV2` Schema

**æª”æ¡ˆ**: `schemas/recommendation.py`

**å‰µå»ºæ–°æª”æ¡ˆ**:

```python
from pydantic import BaseModel, Field
from typing import List, Optional, Literal

class UserInputV2(BaseModel):
    """
    ä½¿ç”¨è€…è¼¸å…¥ v2.0 - ç”¨æ–¼æ™ºæ…§æ¨è–¦
    """

    # åŸºæœ¬è³‡è¨Š
    occasion: Literal["date", "business", "family", "friends", "solo"] = "friends"
    group_size: int = Field(default=2, ge=1, le=20)
    budget_per_person: Optional[int] = Field(default=None, description="æ¯äººé ç®—ï¼ˆå°å¹£ï¼‰")

    # é£²é£Ÿé™åˆ¶ï¼ˆç¡¬éæ¿¾ï¼‰
    dietary_restrictions: List[str] = Field(
        default_factory=list,
        description="e.g., ['no_beef', 'no_pork', 'no_seafood', 'vegan', 'no_spicy']"
    )

    # éæ•åŸ
    allergens: List[str] = Field(
        default_factory=list,
        description="e.g., ['nuts', 'shrimp', 'milk']"
    )

    # åå¥½ï¼ˆè»Ÿæ’åºï¼‰
    preferred_flavors: List[str] = Field(
        default_factory=list,
        description="e.g., ['spicy', 'sour', 'sweet']"
    )

    preferred_textures: List[str] = Field(
        default_factory=list,
        description="e.g., ['crispy', 'soup']"
    )

    # å…¶ä»–åå¥½
    avoid_messy_food: bool = Field(default=False, description="ç´„æœƒå ´æ™¯é¿å…æ²¹è†©/éœ€ç”¨æ‰‹æŠ“çš„èœ")
    prefer_signature: bool = Field(default=True, description="å„ªå…ˆæ¨è–¦æ‹›ç‰Œèœ")
```

---

#### Task 6-7: å¯¦ä½œ `RecommendationService`

**æª”æ¡ˆ**: `agent/recommendation.py` (æ–°å»ºæª”æ¡ˆ)

**å®Œæ•´å¯¦ä½œç¯„æœ¬**:

```python
"""
Runtime Recommendation Service
å³æ™‚æ¨è–¦é‚è¼¯ï¼ˆé Agent Loopï¼Œç´” Python + LLMï¼‰
"""

import os
from typing import List, Tuple
import google.generativeai as genai
import json

from schemas.recommendation import UserInputV2
from schemas.restaurant_profile import RestaurantProfile, MenuItem


class RecommendationService:
    """
    å…©éšæ®µæ¨è–¦ç³»çµ±ï¼š
    1. Hard Filter (Python) - çµ•å°æ¢ä»¶éæ¿¾
    2. Soft Ranking (LLM) - å ´æ™¯åŒ¹é…èˆ‡ç†ç”±ç”Ÿæˆ
    """

    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not set")
        genai.configure(api_key=self.api_key)

    async def generate_recommendation(
        self,
        user_input: UserInputV2,
        profile: RestaurantProfile
    ) -> dict:
        """
        ä¸»è¦æ¨è–¦æµç¨‹

        Returns:
            {
                "recommended_dishes": List[MenuItem],
                "reasoning": str,
                "total_price": int,
                "warnings": List[str]
            }
        """

        # STEP 1: Hard Filter (Python)
        candidates = self._hard_filter(user_input, profile.menu_items)

        if not candidates:
            return {
                "recommended_dishes": [],
                "reasoning": "æ‰¾ä¸åˆ°ç¬¦åˆæ‚¨æ¢ä»¶çš„èœè‰²ï¼Œè«‹èª¿æ•´ç¯©é¸æ¢ä»¶ã€‚",
                "total_price": 0,
                "warnings": ["ç„¡ç¬¦åˆèœè‰²"]
            }

        # STEP 2: Soft Ranking (LLM)
        final_dishes, reasoning = await self._soft_ranking(
            user_input, candidates
        )

        # STEP 3: Calculate total
        total_price = sum(d.price or 0 for d in final_dishes)

        # STEP 4: Generate warnings
        warnings = self._generate_warnings(user_input, final_dishes, total_price)

        return {
            "recommended_dishes": final_dishes,
            "reasoning": reasoning,
            "total_price": total_price,
            "warnings": warnings
        }

    def _hard_filter(
        self,
        user_input: UserInputV2,
        all_dishes: List[MenuItem]
    ) -> List[MenuItem]:
        """
        ç¡¬éæ¿¾é‚è¼¯ï¼ˆPython ç´”é‹ç®—ï¼Œä¸ä½¿ç”¨ LLMï¼‰
        """
        candidates = []

        for dish in all_dishes:
            # è·³éæ²’æœ‰å±¬æ€§çš„èœï¼ˆfallback dishï¼‰
            if not dish.analysis:
                continue

            # é ç®—éæ¿¾ï¼ˆå…è¨± 10% å½ˆæ€§ï¼‰
            if user_input.budget_per_person:
                max_price = user_input.budget_per_person * 0.9
                if dish.price and dish.price > max_price:
                    continue

            # é£²é£Ÿé™åˆ¶éæ¿¾
            if "no_beef" in user_input.dietary_restrictions and dish.analysis.contains_beef:
                continue
            if "no_pork" in user_input.dietary_restrictions and dish.analysis.contains_pork:
                continue
            if "no_seafood" in user_input.dietary_restrictions and dish.analysis.contains_seafood:
                continue
            if "vegan" in user_input.dietary_restrictions and not dish.analysis.is_vegan:
                continue
            if "no_spicy" in user_input.dietary_restrictions and dish.analysis.is_spicy:
                continue

            # éæ•åŸéæ¿¾
            if any(allergen in dish.analysis.allergens for allergen in user_input.allergens):
                continue

            # ç´„æœƒå ´æ™¯ç‰¹æ®Šéæ¿¾
            if user_input.avoid_messy_food:
                messy_textures = ["soup", "messy", "sauce_heavy"]
                if any(t in dish.analysis.textures for t in messy_textures):
                    continue

            # é€šéæ‰€æœ‰éæ¿¾
            candidates.append(dish)

        print(f"[RecommendationService] Hard filter: {len(all_dishes)} â†’ {len(candidates)} candidates")
        return candidates

    async def _soft_ranking(
        self,
        user_input: UserInputV2,
        candidates: List[MenuItem]
    ) -> Tuple[List[MenuItem], str]:
        """
        ä½¿ç”¨ LLM é€²è¡Œå ´æ™¯åŒ¹é…èˆ‡æ’åº
        """

        # é™åˆ¶å€™é¸èœæ•¸é‡ï¼ˆé¿å… prompt éé•·ï¼‰
        if len(candidates) > 30:
            # å„ªå…ˆä¿ç•™æ‹›ç‰Œèœå’Œé«˜è©•åˆ†èœ
            candidates = sorted(
                candidates,
                key=lambda d: (
                    d.analysis.is_signature if d.analysis else False,
                    d.analysis.sentiment_score if d.analysis else 0
                ),
                reverse=True
            )[:30]

        # å»ºç«‹å€™é¸èœè³‡è¨Šï¼ˆç°¡åŒ–ç‰ˆï¼Œé¿å…éé•·ï¼‰
        candidates_info = []
        for d in candidates:
            info = {
                "name": d.name,
                "price": d.price,
                "category": d.category,
            }
            if d.analysis:
                info["is_signature"] = d.analysis.is_signature
                info["sentiment_score"] = d.analysis.sentiment_score
                info["highlight"] = d.analysis.highlight_review or "ç„¡ç‰¹åˆ¥è©•åƒ¹"
                info["flavors"] = d.analysis.flavors
                info["occasions"] = d.analysis.suitable_occasions
            candidates_info.append(info)

        # å»ºç«‹ Prompt
        model = genai.GenerativeModel('gemini-1.5-flash')  # å¿«é€Ÿæ¨¡å‹

        prompt = f"""
ä½ æ˜¯å°ˆæ¥­çš„é¤å»³ç¶“ç†ã€‚å®¢äººè³‡è¨Šå¦‚ä¸‹ï¼š

- ç”¨é¤å ´æ™¯ï¼š{user_input.occasion}
- äººæ•¸ï¼š{user_input.group_size} äºº
- é ç®—ï¼ˆæ¯äººï¼‰ï¼š{user_input.budget_per_person or 'ä¸é™'}
- åå¥½å£å‘³ï¼š{', '.join(user_input.preferred_flavors) or 'ç„¡ç‰¹åˆ¥åå¥½'}

å€™é¸èœå–®ï¼ˆå·²éæ¿¾ä¸ç¬¦åˆæ¢ä»¶çš„èœè‰²ï¼‰ï¼š
{json.dumps(candidates_info, ensure_ascii=False, indent=2)}

è«‹å®Œæˆä»¥ä¸‹ä»»å‹™ï¼š

1. å¾å€™é¸èœä¸­æŒ‘é¸ 3-5 é“æœ€é©åˆçš„çµ„åˆ
2. ç¢ºä¿ï¼š
   - å ´æ™¯åŒ¹é…ï¼ˆä¾‹å¦‚ç´„æœƒé¿é–‹å¤§è’œé‡ã€æ²¹è†©èœï¼‰
   - å£å‘³å¹³è¡¡ï¼ˆæœ‰ä¸»é£Ÿã€è”¬èœã€è‚‰é¡ï¼‰
   - åƒ¹æ ¼åˆç†ï¼ˆç¸½åƒ¹ä¸è¶…éé ç®—ï¼‰
   - å„ªå…ˆé¸æ“‡æ‹›ç‰Œèœï¼ˆis_signature: trueï¼‰

3. å›å‚³ JSON æ ¼å¼ï¼š
{{
  "selected_dish_names": ["èœå1", "èœå2", "èœå3"],
  "reasoning": "æ¨è–¦ç†ç”±èªªæ˜ï¼ˆ2-3 å¥è©±ï¼Œå¼•ç”¨ highlight å…§å®¹ï¼‰"
}}
"""

        try:
            response = await model.generate_content_async(prompt)
            result_text = response.text

            # æ¸…ç† JSON
            if result_text.startswith("```json"):
                result_text = result_text[len("```json"):].strip()
            if result_text.endswith("```"):
                result_text = result_text[:-len("```")].strip()

            result = json.loads(result_text)

            # æ ¹æ“š LLM å›å‚³çš„åç¨±æ‰¾å‡ºå¯¦éš›çš„ MenuItem
            selected_names = set(result.get("selected_dish_names", []))
            final_dishes = [d for d in candidates if d.name in selected_names]
            reasoning = result.get("reasoning", "AI æ¨è–¦çµ„åˆ")

            print(f"[RecommendationService] LLM selected {len(final_dishes)} dishes")
            return final_dishes, reasoning

        except Exception as e:
            print(f"[RecommendationService] LLM ranking error: {e}")
            # Fallback: å›å‚³å‰ 3 å€‹æ‹›ç‰Œèœ
            fallback = sorted(
                candidates,
                key=lambda d: d.analysis.is_signature if d.analysis else False,
                reverse=True
            )[:3]
            return fallback, "ç³»çµ±è‡ªå‹•æ¨è–¦ï¼ˆæ‹›ç‰Œèœå„ªå…ˆï¼‰"

    def _generate_warnings(
        self,
        user_input: UserInputV2,
        dishes: List[MenuItem],
        total_price: int
    ) -> List[str]:
        """
        ç”Ÿæˆè­¦å‘Šè¨Šæ¯
        """
        warnings = []

        # é ç®—è­¦å‘Š
        if user_input.budget_per_person:
            expected_total = user_input.budget_per_person * user_input.group_size
            if total_price > expected_total * 1.1:
                warnings.append(f"ç¸½åƒ¹ ${total_price} è¶…å‡ºé ç®—ç´„ {int((total_price / expected_total - 1) * 100)}%")

        # èœè‰²æ•¸é‡è­¦å‘Š
        if len(dishes) < 2:
            warnings.append("èœè‰²è¼ƒå°‘ï¼Œå»ºè­°å†åŠ é»")

        if len(dishes) < user_input.group_size:
            warnings.append(f"{user_input.group_size} äººç”¨é¤å»ºè­°è‡³å°‘ {user_input.group_size} é“èœ")

        return warnings
```

---

#### Task 8: å»ºç«‹æ¨è–¦ API ç«¯é»

**æª”æ¡ˆ**: `api/v1/recommend.py` (æ–°å»ºæª”æ¡ˆ)

```python
from fastapi import APIRouter, HTTPException, BackgroundTasks
from schemas.recommendation import UserInputV2
from schemas.restaurant_profile import RestaurantProfile
from services import firestore_service
from agent.recommendation import RecommendationService
from services.pipeline import RestaurantPipeline

router = APIRouter()

@router.post("/recommend/{place_id}")
async def get_recommendation(
    place_id: str,
    user_input: UserInputV2,
    background_tasks: BackgroundTasks
):
    """
    æ™ºæ…§æ¨è–¦ç«¯é»

    Flow:
    1. æª¢æŸ¥ Firestore æ˜¯å¦æœ‰ Profile
    2. è‹¥ç„¡ â†’ è§¸ç™¼ Background Pipeline â†’ å›å‚³ 202 Accepted
    3. è‹¥æœ‰ â†’ åŸ·è¡Œæ¨è–¦ â†’ å›å‚³ 200 OK
    """

    # æŸ¥è©¢ Profile
    profile = firestore_service.get_restaurant_profile(place_id)

    if not profile:
        # Cold Start: è§¸ç™¼ Pipeline
        print(f"[RecommendAPI] Cold start for {place_id}, triggering pipeline")

        # éœ€è¦é¤å»³åç¨±ä¾†å•Ÿå‹• pipelineï¼ˆå¾å“ªè£¡å–å¾—ï¼Ÿï¼‰
        # é¸é … 1: è¦æ±‚ client æä¾› name
        # é¸é … 2: ä½¿ç”¨ Google Places API æŸ¥è©¢

        # é€™è£¡å…ˆå›å‚³ 202ï¼ˆå¯¦éš›ä¸Šæ‡‰è©²è¦ SSE æˆ– WebSocketï¼‰
        background_tasks.add_task(_run_pipeline_async, place_id, "restaurant_name_here")

        return {
            "status": "processing",
            "message": "æ­£åœ¨è™•ç†é¤å»³è³‡æ–™ï¼Œè«‹ç¨å¾Œé‡è©¦",
            "estimated_time": "30-60 seconds"
        }, 202

    # Warm Start: åŸ·è¡Œæ¨è–¦
    service = RecommendationService()
    result = await service.generate_recommendation(user_input, profile)

    return result

async def _run_pipeline_async(place_id: str, name: str):
    """èƒŒæ™¯ä»»å‹™ï¼šåŸ·è¡Œ Pipeline"""
    try:
        pipeline = RestaurantPipeline()
        profile = await pipeline.process(name)

        if profile:
            # ç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„ place_id
            profile.place_id = place_id
            firestore_service.save_restaurant_profile(profile)
            print(f"[Background] Pipeline completed for {place_id}")
        else:
            print(f"[Background] Pipeline failed for {place_id}")
    except Exception as e:
        print(f"[Background] Pipeline error: {e}")
```

**æ•´åˆåˆ° main.py**:

```python
# åœ¨ main.py ä¸­åŠ å…¥
from api.v1.recommend import router as recommend_router

app.include_router(recommend_router, prefix="/api/v1")
```

---

### Phase 3: æ¸¬è©¦èˆ‡å„ªåŒ–

#### Task 11-13: æ¸¬è©¦è¨ˆåŠƒ

**å»ºç«‹æ¸¬è©¦æª”æ¡ˆ**: `tests/test_recommendation.py`

```python
import pytest
from schemas.recommendation import UserInputV2
from schemas.restaurant_profile import MenuItem, DishAttributes
from agent.recommendation import RecommendationService

def test_hard_filter_no_beef():
    """æ¸¬è©¦ç„¡ç‰›è‚‰éæ¿¾"""
    service = RecommendationService()

    dishes = [
        MenuItem(
            name="ç‰›è‚‰éºµ",
            price=150,
            analysis=DishAttributes(contains_beef=True)
        ),
        MenuItem(
            name="é›è‚‰é£¯",
            price=80,
            analysis=DishAttributes(contains_beef=False)
        )
    ]

    user_input = UserInputV2(dietary_restrictions=["no_beef"])

    result = service._hard_filter(user_input, dishes)

    assert len(result) == 1
    assert result[0].name == "é›è‚‰é£¯"

# æ›´å¤šæ¸¬è©¦...
```

---

## ğŸš€ éƒ¨ç½²æµç¨‹

**é‡æ–°éƒ¨ç½²**:

```bash
gcloud builds submit --config=cloudbuild.yaml --project=gen-lang-client-0415289079
```

**æ¸¬è©¦ API**:

```bash
# æ¸¬è©¦æ¨è–¦ç«¯é»
curl -X POST "https://oderwhat-staging-u33peegeaa-de.a.run.app/api/v1/recommend/ChIJ..." \
  -H "Content-Type: application/json" \
  -d '{
    "occasion": "date",
    "group_size": 2,
    "budget_per_person": 500,
    "dietary_restrictions": ["no_spicy"],
    "avoid_messy_food": true
  }'
```

---

## ğŸ“ æ³¨æ„äº‹é …

1. **ç’°å¢ƒè®Šæ•¸ç¢ºèª**:
   - `GEMINI_API_KEY` å¿…é ˆè¨­å®š
   - `APIFY_API_TOKEN` å¿…é ˆè¨­å®š
   - `SERPER_API_KEY` å¿…é ˆè¨­å®š

2. **æ•ˆèƒ½ç›®æ¨™**:
   - æ¨è–¦ API å›æ‡‰æ™‚é–“ < 5 ç§’
   - Hard Filter æ‡‰åœ¨ < 100ms
   - LLM Ranking æ‡‰åœ¨ < 3 ç§’

3. **éŒ¯èª¤è™•ç†**:
   - æ‰€æœ‰ async å‡½å¼éƒ½è¦æœ‰ try-except
   - JSON è§£æå¤±æ•—è¦æœ‰ fallback
   - LLM å¤±æ•—è¦å›å‚³é è¨­æ¨è–¦

---

## ğŸ’¡ çµ¦ä¸‹ä¸€å€‹ LLM çš„æç¤º

ç•¶æ‚¨ç¹¼çºŒé–‹ç™¼æ™‚ï¼š

1. å…ˆé–±è®€ `specs/architecture_v2_pipeline.md` äº†è§£æ•´é«”æ¶æ§‹
2. æŸ¥çœ‹ `schemas/restaurant_profile.py` äº†è§£è³‡æ–™çµæ§‹
3. æŒ‰ç…§ Task 3 â†’ Task 4 â†’ Task 5-7 â†’ Task 8 çš„é †åºå¯¦ä½œ
4. æ¯å®Œæˆä¸€å€‹ Task å°±æ¸¬è©¦ä¸€æ¬¡
5. é‡åˆ°å•é¡Œå…ˆæŸ¥çœ‹ Cloud Run æ—¥èªŒ

**ç¥é–‹ç™¼é †åˆ©ï¼** ğŸ‰
